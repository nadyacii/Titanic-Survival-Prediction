# -*- coding: utf-8 -*-
"""Titanic Survival Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DCalPUxjtjdSVKMnM-QeEOmk55hVDw_Q

# TITANIC SURVIVAL PREDICTION

by Nadia Chusnul I

## LOAD PACKAGE
"""

import warnings
warnings.filterwarnings("ignore")

# Commented out IPython magic to ensure Python compatibility.
# import numpy and pandas for data manipulating and data analysis
import pandas as pd
import numpy as np

# import matplotlib and seaborn for plotting
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

#import scikit learn for modelling
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#scikit learn for model
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, auc, roc_curve

# scikit learn for categorical variables
from sklearn.preprocessing import LabelEncoder

# scikit learn for scaling
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# file system management
import os

# Set pandas display
pd.set_option('display.max_columns',None)
pd.set_option('display.max_rows',None)

# Set plot style and size for better visualization
sns.set_theme(context='notebook',
              style='whitegrid',
              palette='seismic',
              font_scale=1.5,
              rc=None)
import matplotlib
matplotlib.rcParams['figure.figsize'] = [8, 8]
matplotlib.rcParams.update({'font.size': 15})

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/tested.csv')

"""## DATA UNDERSTANDING"""

# Show 5 rows of the DataFrame
df.head()

# Show last 5 rows of the DataFrame
df.tail()

# Print shape and size of dataset
print('Shape of Titanic data set is :',df.shape)
print('Size of Titanic data set is  :',df.size)

# Summary statistics of the DataFrame
df.describe()

# Information of Dataset
df.info()

# Plot histogram for Age column
df['Age'].plot(kind='hist', bins=20, title='Age', edgecolor='black')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.xlabel("Age")
plt.ylabel("Frequency")
plt.show()

# Plot of Fare distribution
sns.histplot(data=df, x="Fare", hue="Embarked",palette="tab10");

# Aggregate statistics for Fare and Age Columns
df.agg(
    {
        "Fare": ["min", "max", "median", "mean","skew",'std'],
        "Age": ["min", "max", "median", "mean","skew",'std'],
    }
)

# Copy of dataset
dftitanic=df.copy()

"""## DATA PREPARATIION"""

# Information of dataset
df.info()

# Count the number of unique values in categorical column
df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)

"""Count and Percentage Plot"""

# Create chart for Sex distribution
soft_colors = sns.color_palette("pastel")

plt.figure(figsize=(14,6))

# Bar Chart
ax1 = plt.subplot(1,2,1)
bars = sns.countplot(x='Sex', data=df, palette=soft_colors, ax=ax1)
plt.title("Sex", fontsize=20)

# Label
for bar in bars.patches:
    height = bar.get_height()
    bars.annotate(
        f'{int(height)}',
        xy=(bar.get_x() + bar.get_width() / 2, height),
        xytext=(0, 3),
        textcoords="offset points",
        ha='center', va='bottom', fontsize=12
    )

# Pie Chart
ax2 = plt.subplot(1,2,2)
sex_counts = df['Sex'].value_counts()
ax2 = sex_counts.plot.pie(
    explode=[0.05] * len(sex_counts),
    autopct='%1.2f%%',
    shadow=False,
    startangle=90,
    colors=soft_colors,
    labels=sex_counts.index
)
ax2.set_ylabel('')
ax2.set_title("Sex", fontsize=20, color='Red')

plt.tight_layout()
plt.show()

# Create chart for Embarked distribution
soft_colors = sns.color_palette("pastel")

plt.figure(figsize=(14,6))

# Bar Chart
ax1 = plt.subplot(1,2,1)
bars = sns.countplot(x='Embarked', data=df, palette=soft_colors, ax=ax1)
plt.title("Embarked", fontsize=20)

# Label
for bar in bars.patches:
    height = bar.get_height()
    bars.annotate(
        f'{int(height)}',
        xy=(bar.get_x() + bar.get_width() / 2, height),
        xytext=(0, 3),
        textcoords="offset points",
        ha='center', va='bottom', fontsize=12
    )

# Pie Chart
ax2 = plt.subplot(1,2,2)
sex_counts = df['Embarked'].value_counts()
ax2 = sex_counts.plot.pie(
    explode=[0.05] * len(sex_counts),
    autopct='%1.2f%%',
    shadow=False,
    startangle=90,
    colors=soft_colors,
    labels=sex_counts.index
)
ax2.set_ylabel('')
ax2.set_title("Embarked", fontsize=20, color='Red')

plt.tight_layout()
plt.show()

# Create chart for Survived distribution
soft_colors = sns.color_palette("pastel")

plt.figure(figsize=(14,6))

# Bar Chart
ax1 = plt.subplot(1,2,1)
bars = sns.countplot(x='Survived', data=df, palette=soft_colors, ax=ax1)
plt.title("Survived", fontsize=20)

# Label
for bar in bars.patches:
    height = bar.get_height()
    bars.annotate(
        f'{int(height)}',
        xy=(bar.get_x() + bar.get_width() / 2, height),
        xytext=(0, 3),
        textcoords="offset points",
        ha='center', va='bottom', fontsize=12
    )

# Pie Chart
ax2 = plt.subplot(1,2,2)
sex_counts = df['Survived'].value_counts()
ax2 = sex_counts.plot.pie(
    explode=[0.05] * len(sex_counts),
    autopct='%1.2f%%',
    shadow=False,
    startangle=90,
    colors=soft_colors,
    labels=sex_counts.index
)
ax2.set_ylabel('')
ax2.set_title("Survived", fontsize=20, color='Red')

plt.tight_layout()
plt.show()

# Create chart for SibSp distribution
soft_colors = sns.color_palette("pastel")

plt.figure(figsize=(14,6))

# Bar Chart
ax1 = plt.subplot(1,2,1)
bars = sns.countplot(x='SibSp', data=df, palette=soft_colors, ax=ax1)
plt.title("SibSp", fontsize=20)

# Label
for bar in bars.patches:
    height = bar.get_height()
    bars.annotate(
        f'{int(height)}',
        xy=(bar.get_x() + bar.get_width() / 2, height),
        xytext=(0, 3),
        textcoords="offset points",
        ha='center', va='bottom', fontsize=12
    )

# Pie Chart
ax2 = plt.subplot(1,2,2)
sex_counts = df['SibSp'].value_counts()
ax2 = sex_counts.plot.pie(
    explode=[0.05] * len(sex_counts),
    autopct='%1.2f%%',
    shadow=False,
    startangle=90,
    colors=soft_colors,
    labels=sex_counts.index
)
ax2.set_ylabel('')
ax2.set_title("SibSp", fontsize=20, color='Red')

plt.tight_layout()
plt.show()

# Create chart for Parch distribution
soft_colors = sns.color_palette("pastel")

plt.figure(figsize=(14,6))

# Bar Chart
ax1 = plt.subplot(1,2,1)
bars = sns.countplot(x='Parch', data=df, palette=soft_colors, ax=ax1)
plt.title("Parch", fontsize=20)

# Label
for bar in bars.patches:
    height = bar.get_height()
    bars.annotate(
        f'{int(height)}',
        xy=(bar.get_x() + bar.get_width() / 2, height),
        xytext=(0, 3),
        textcoords="offset points",
        ha='center', va='bottom', fontsize=12
    )

# Pie Chart
ax2 = plt.subplot(1,2,2)
sex_counts = df['Parch'].value_counts()
ax2 = sex_counts.plot.pie(
    explode=[0.05] * len(sex_counts),
    autopct='%1.2f%%',
    shadow=False,
    startangle=90,
    colors=soft_colors,
    labels=sex_counts.index
)
ax2.set_ylabel('')
ax2.set_title("Parch", fontsize=20, color='Red')

plt.tight_layout()
plt.show()

"""### Correlation Matrix"""

# Calculate and sort correlations with 'Survived'
numeric_df = df.select_dtypes(include='number')
pd.DataFrame(abs(numeric_df.corr()['Survived'])).sort_values(by='Survived', ascending=False)

# Display correlation matrix
numeric_df.corr().style\
    .background_gradient(cmap='coolwarm')\
    .format(precision=3)

# Heatmap of feature correlations
corr=numeric_df.corr()#["Survived"]
plt.figure(figsize=(20, 15))
sns.heatmap(corr, vmax=.8, linewidths=0.01, square=True,annot=True,cmap='YlGnBu',linecolor="black")
plt.title('Correlation between features')
plt.show()

# correlation heatmap of higly correlated features with SalePrice
hig_corr = numeric_df.corr()
hig_corr_features = hig_corr.index[abs(hig_corr["Fare"]) >= 0.25]
hig_corr_features

# Plot heatmap for high correlation features
plt.figure(figsize=(10,8))
ax = sns.heatmap(df[hig_corr_features].corr(), cmap = "coolwarm", annot=True, linewidth=3)
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.show()

"""## DATA PREPARATION

### Missing Value
"""

# Percentage of missing values in each column
df.isnull().mean().sort_values(ascending=False)*100

# Function to calculate missing values
def missing_value (df):
    missing_Number = df.isnull().sum().sort_values(ascending=False)[df.isnull().sum().sort_values(ascending=False) !=0]
    missing_percent=round((df.isnull().sum()/df.isnull().count())*100,2)[round((df.isnull().sum()/df.isnull().count())*100,2) !=0]
    missing = pd.concat([missing_Number,missing_percent],axis=1,keys=['Missing Number','Missing Percentage'])
    return missing

# Display the missing values
missing_data = missing_value(df)
print(missing_data)

# Plot heatmap to visualize missing values in the DataFrame
sns.heatmap(df.isnull(),cmap='cool');

# Visualize missing data using a bar chart with missingno
import missingno
missingno.bar(df, color="lightblue", sort="ascending", figsize=(10,5), fontsize=12);

"""### Handling Missing Value"""

# Fill missing values in 'Age' column with the mean value
df['Age'] = df['Age'].fillna(df['Age'].mean())

# Filter rows where 'Fare' column has missing values
df[df['Fare'].isnull()]

# Fill missing values in 'Fare' column using backward fill method
df['Fare'] = df['Fare'].fillna(method='bfill')

# Drop the 'Cabin' column from the DataFrame
df = df.drop(['Cabin'],axis=1)

# Visualize missing data pattern using missingno matrix
import missingno as msno
msno.matrix(df)
plt.show()

"""All the missing value is filled/removed

### Outliers
"""

# Plot distribution and boxplot for Age and Fare
plt.figure(figsize=(14,7))

plt.subplot(2,2,1)
sns.distplot(df['Age'],color='Red')
plt.subplot(2,2,2)
sns.boxplot(df['Age'],color='Red')

plt.subplot(2,2,3)
sns.distplot(df['Fare'],color='Red')
plt.subplot(2,2,4)
sns.boxplot(df['Fare'],color='Red')

plt.tight_layout()
plt.show()

# Calculate and sort IQR for numeric columns
numeric_df = df.select_dtypes(include='number')

Q1 = numeric_df.quantile(0.02)
Q3 = numeric_df.quantile(0.98)
IQR = Q3 - Q1

IQR.sort_values(ascending=False)

# Remove outliers from DataFrame based on IQR method
titanic = df[~((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Visualize Age and Fare with distribution and boxplot
plt.figure(figsize=(14,7))

plt.subplot(2,2,1)
sns.distplot(df['Age'],color='Green')
plt.subplot(2,2,2)
sns.boxplot(df['Age'],color='Green')

plt.subplot(2,2,3)
sns.distplot(df['Fare'],color='Green')
plt.subplot(2,2,4)
sns.boxplot(df['Fare'],color='Green')

plt.tight_layout()
plt.show()

"""### Visualization"""

# Scatter plot of Fare vs Age
df_fig = sns.FacetGrid(df, col='Sex', hue='Survived',height=6,aspect=1.6)
df_fig.map(plt.scatter,'Fare','Age' )
plt.show()

# Bar plot showing the number of unique values per column
plt.figure(figsize=(14,6))

df.nunique().plot(kind='bar')
plt.title('No of unique values in the dataset')
plt.show()

# Pairplot to explore relationships between Age, Fare, and Survived
sns.pairplot(df, vars=['Age', 'Fare', 'Survived'], hue='Sex', palette='plasma', aspect=1.9)
sns.pairplot(df,vars=['Age','Fare','Survived'],hue='Sex',palette='plasma',aspect=1.9);

# Identify and print numerical and categorical columns
numerical = df.select_dtypes(include=['number']).columns
categorical = df.select_dtypes(include=['object']).columns

print('Numerical  :',numerical)
print("Categorical:",categorical)

# Print value counts
for col in df[['Sex', 'Embarked','Survived','Pclass','SibSp','Parch']]:
    print(df[col].value_counts())
    print("-----"*7)

"""### Converted Column"""

# Drop Name and Ticket columns from the DataFrame
df = df.drop (['Name', 'Ticket'], axis=1)

# Display the first 5 rows of the DataFrame
df.head()

# Encode Sex and Embarked columns into numeric values
df['Sex'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)
df['Embarked'] = df['Embarked'].map({'S': 0, 'Q': 1, 'C': 2}).astype(int)

# Display the first 5 rows of the DataFrame
df.head()

# Print data types of Sex and Embarked columns
print(df[['Sex', 'Embarked']].dtypes)

"""### Train Test Split"""

# Split dataset into features (X) and target (y)
X = df.drop(['Survived'],axis=1)
y = df['Survived']

# Split the data into training and testing sets
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=21)

"""### Scaling Data"""

# Scale the features using MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = pd.DataFrame(X_train, columns=X.columns)
X_test = pd.DataFrame(X_test, columns=X.columns)

# Display the first 5 rows of the scaled training and testing data
display(X_train.head())
display(X_test.head())

"""## MODEL IMPLEMENTATION"""

# Train a Logistic Regression model and evaluate its accuracy
lr = LogisticRegression(max_iter=1000, random_state=21)
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))

"""## EVALUATION"""

# Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Not Survived', 'Survived'],
            yticklabels=['Not Survived', 'Survived'])

plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

# Print the classification report to evaluate model performance
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""##CONCLUSION

The Logistic Regression model that has been created demonstrates excellent performance based on the displayed confusion matrix. The model is able to classify the entire test data with 100% accuracy, where all 54 passengers who did not survive and all 30 passengers who survived were correctly predicted without any errors. This is reflected in the precision, recall, and F1-score values, all of which reached perfect scores of 1.0.

"""